# -*- coding: utf-8 -*-
"""Lab01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v5NOsqSb4svoGXvbFO9WohCqrKR5T_ka

# Lab session 1: Data

## Introduction

The aim of this lab is for students to familiarise with  **basic exploratory data analysis** of a sample dataset, and more specifically with the concepts of **summary statistics** and **data visualisation** covered in week 2. We will use  the Python's **pandas** package in this **notebook** environment.

<font color = 'maroon'>*This session <ins>is a warm-up that will not count toward your final grade</ins>.*</font>

### Before we start:

This environment that allows us to enter both text and run codes interactively, is a web-based user-friendly environment called [Jupyter notebook](https://jupyter.org/).

There are two types of cells: *Text* and *Code*. You can add your own cells. You can also edit the texts by double-clicking on them. It follows the [markup rules](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet).

In order to execute (run) a cell, you can use one of the following ways:

0. `Shift + Enter` : executes a cell and goes to the next one.
1. `Ctrl + Enter` : executes a block but stays at the same block. This is equivalent to clicking on the *run* button to the left of the cell, which appears when you hover the mouse over the `[ ]` icon.
2. Use the `Runtime` tab (at the top of the page), which gives you more options as well.

Now, test your knowledge by running the next cell (the output should appear right after):
"""

for i in range(5):
  print('{:2d} - Welcome to the Data Mining lab!'.format(2**i))

"""As you might have noticed, we will be using Python codes. Let's have a word on why `Python`?

*Well, for one, it is the most preferred language among data scientist, according to [this poll](https://www.kdnuggets.com/2018/05/poll-tools-analytics-data-science-machine-learning-results.html).
Also it helps that it is a general purpose programming language with a simple syntax. It also has a lot of great open-source libraries -- which, in Python, we call them `packages` -- developed by an active community. If interested, [read more](https://www.cbtnuggets.com/blog/technology/data/why-data-scientists-love-python) on why Python is particularly so popular among data scientist.*

### Some more `notebook` cool tricks:

- You can use the **`tab`** button for auto-completing. You can also use `tab` after a **`dot`** to be shown a drop-down list of the available attributes and methods on an object or a class. For instance, let's create a string object called `mystring` (by executing the first cell), and use the `tab` key after a `dot` to see a list of available attributes and methods for a string object in Python (in the second cell: don't run it, just use the tab key after dot!).
"""

mystring = '   Hello, World!'

mystring.format

"""Note that in Python, every variable is an object. Also by now, you should have noticed that we do not need to explicitly declare variables and their types in Python before using them.

Another thing to keep in mind is that objects and functions (runtime variables) persist between different cells in the same notebook session. If you want to clear the memory, you can choose "`Reset all runtimes...`" under the "`Runtime`" tab from the top-left menu.

- Another useful point about the `notebook` environment is that if you want to get help on anything (a method, a function, an object, etc), you can just put a question mark in front of it and execute that line. For instance, let's get help on what the `strip` method does on a string object, by executing the following cell:
"""

mystring.strip?
# This opens the help on the method "strip" at the bottom of this
# page. You can close the help page after reading it.
# By the way, this is how we designate a comment line in Python!

"""From now on, we may give a hint about answering a question by putting a question mark in front of a command to open the help page for it for you. Your task is to complete the command."""

print(mystring)
print(mystring.strip())

"""## 1.   Explore the Dataset -- using Python's `Pandas`

Here, we are going to perform some basic *exploratory data analysis* on some sample data.
Data exploration refers to the preliminary investigation of data in order
to better understand its specific characteristics. There are two key motivations for data exploration:
1. To help users select the appropriate preprocessing and data analysis technique used.
2. To make use of humans' abilities to recognize patterns in the data.

The data is about the "cars for sale", which was collected in Summer 2014 from the website _Autotrader.com_,  by one of our MSc student who worked on a data mining project. The data is saved in a CSV file, called **`LondonCars.csv`**.

---
> **Q0:** Why are such files called `CSV`? (Find out what CSV stands for. It may also help to try and open the file using a basic text editor).

> **A0:** (*you can use this space to write your answer for your own note taking! Just double-click on this cell*)
---

### 1.1   Upload the CSV file to this machine.

>-   On the left side of this page, click on the arrow to "Open the left pane".
-   From the "Files" tab, click on `UPLOAD`
- Choose the CSV file that you downloaded from QM+ to your local machine, to be uploaded to *this machine*.

>_Note:_ *By "this machine", we mean the virtual machine that is allocated to your account and running this notebook, hosted by Google Compute Engine. Note that next time you log in, the file may be gone and needs to be re-uploaded, as Google recycles Virtual machines when they are idle for a while.*

### 1.2   Load the dataset from the CSV file:

We will use a package in Python called [pandas](https://pandas.pydata.org/): it has many useful features to work with structured data, and is popular for its ease of use (and as is the case for any Python package, it is [open-source](https://github.com/pandas-dev/pandas)).

So, let's start by reading the csv file into a `pandas' DataFrame`:

(Note that we use **`import`** to (guess what) import a package in Python! We can also assign a different name (alias) to it, usually a shorthand name for convenience. For example, we typically `import pandas as pd`)

Execute the following code block.
"""

import pandas as pd
df = pd.read_csv('./LondonCars2014.csv')

"""Let's get more information about the `read_csv` method that we used by executing the following cell:"""



pd.read_csv

"""---
> **Q1:** You should notice that the command has many options. When these options are not specified, their default values are taken. For example, find out what these default values were for our `read_csv`. Also find out, in particular, what the options `sep`, `header`, `index_col`, `usecols`, `dtype`, `na_values`, and `encoding` do.

> **A1:**
---

### 1.3   Get general information about the data:

So far, we have read the csv file into a variable we called **`df`**: it is a pandas `DataFrame` object that contains the information in the csv file, along with many useful attributes and methods. For instance, let's print the first few entries along with the column names, to get a quick feeling about the data:
"""

df.head()

"""We still don't know if the data-types are read correctly, we didn't specify them. The `info` method gives us a summary information:"""

df.info

"""You should notice that the data-types are not exactly correct. For instance, the type for the `Doors` attribute (column) is inferred as numeric (64-bit integer), but this is wrong (why?).

So let's fix them!
"""

df = df.astype({'Make':'category', 'Model':'category', 'Year':'category',
                'Mileage':'int32', 'Price':'int64', 'Body Style':'category',
                'Ex Color':'category' , 'In Color':'category',
                'Engine':'category', 'Transmission':'category', 'Doors':'category'})

# Now, use the `info` method again to check if it had the desired effect:

"""---
> **Q2:** You should also notice a change between the reported `memory usage` (the last line reported by the `info` method). What is the change? How do you explain the change?

> **A2:**
---

## 2. Basic exploratory questions using Python

Here we compute various summary statistics, which are quantities, such as the mean and standard deviation, that capture various characteristics of a potentially large set of values with a single number or a small set of numbers.

---
> **Q3:** Use the provided hints to answer the questions about exploring your dataset.

> a. How many instances does the dataset have?
"""

# hint: interpret the output of the following code:
print(df.shape)

"""> b. How many attributes?"""

# again, you can answer the question by interpreting the output of the same code:
print(df.shape)

"""> c. What are the attributes?"""

# a pandas dataframe has an attribute called columns:
print(df.columns)

"""> d. What are the possible values for **Body Style** & **External Color**?"""

# the "unique" method helps:
print('Possible body styles:')
print(df['Body Style'].unique())

# now your turn, for external colour:
print('Possible external colours:')
print('?')

"""> e. What is the *minimum*, *maximum*, *average*, *median* and *standard deviation* price?"""

# these are easy, to get the minimum:
print('min = {}'.format(df['Price'].min()))
# now, you do the rest:
print('max = {}'.format('?'))
print('mean = {}'.format('?'))
print('median = {}'.format('?'))
print('Standard deviation = {}'.format('?'))

"""> f. Why might the median price be different than the average price?

> g. What is the most common year of car?
"""

# hint: you can either use the 'mode()' method,
# or the value_counts() along with idxmax()
print('?')

"""> h. What is the average price of a Honda car and what is the average price a Mercedes-Benz car? **Hint:** Try $\texttt{df.loc}$."""

# For Honda:
print('Average price of a Honda car = {:.2f}'.format(df.loc[df['Make'] == 'Honda']['Price'].mean()))
# Now you do for Mercedes-Benz:
print('Average price of a Mercedes-Benz car = {:.2f}'.format((df.loc[df['Make'] == 'Mercedes-Benz']['Price'].mean())))

"""> i. What is the ratio of 2-door to 4-door cars?"""

# Hint: you can use the output of the value_counts()...
print(df['Doors'].value_counts())
print('The ratio of 2-door to 4-door cars is: {}'.format('?'))

"""> j. It is also possible to display the summary for all the attributes simultaneously in a table using the describe() function. If an attribute is quantitative, it will display its mean, standard deviation and various quantiles (including minimum, median, and maximum) values. If an attribute is qualitative, it will display its number of unique values and the top (most frequent) values.

**<font color="red"></font>**
"""

df.describe(include='all')

"""Note that count refers to the number of non-missing values for each attribute.

> k. For multivariate statistics, you can compute the covariance and correlation between pairs of attributes.

**<font color="red"></font>**
"""

print('Covariance:')
df.cov()

print('Correlation:')
df.corr()

"""---

## 3. Basic data visualisation using Python

Data visualization is the display of information in a graphic or tabular format. Successful visualization requires that the data (information) be converted into a visual format so that the characteristics of the data and the relationships among data items or attributes can be analyzed or reported.

---
> To display the histogram for the milieage attribute by discretizing it into 8 separate bins and counting the frequency for each bin, run this code:

**<font color="red"></font>**
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

df['Mileage'].hist(bins=8)

"""> A boxplot can also be used to show the distribution of values for each attribute.

**<font color="red"></font>**
"""

df.boxplot()

"""> We can finally plot pairwise relationships in a dataset by running the code below. By default, this function will create a grid of axes such that each numeric variable in our dataset will be shared across the y-axes across a single row and the x-axes across a single column. In the diagonal plots, a univariate distribution plot is drawn to show the marginal distribution of the data in each column. Here scatterplot() is used for each pairing of the variables and histplot() for the marginal plots along the diagonal.

**<font color="red"></font>**
"""

import seaborn as sns
import matplotlib.pyplot as plt
sns.pairplot(df)

"""---
> **Q4:** Execute the command above and interpret what the plot is showing. In particular, describe the general trend between `mileage` and `price`, as well as `mileage` and `year`.

> **A4:**
---
"""
